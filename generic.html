<!DOCTYPE HTML>

<html>
	<head>
		<title>Generic Page -Nelson's portolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Nelson</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li class="active"><a href="generic.html">Projects</a></li>
							<li><a href="elements.html">Articles</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://twitter.com/Nelson_Christof" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://www.linkedin.com/in/nelson-ogbeide-013569171/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/Nelsonchris1" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
<div id="main">

						

							<div id="main">

								<!-- Featured Post -->
									<article class="post featured">
										<header class="major">
											<h2>Nelson's Projects</h2>
											<p>This page contains project for both data science and data engineering with github repo links</p>
										</header>
										<ul class="actions special">
										</ul>
									</article>
		
								<!-- Posts -->
									<section class="posts">
										<article>
											<header>
												<span class="date">data engineering (Streaming pipeline)</span>
												<h2><a href="https://github.com/Nelsonchris1/kafka-and-lambda-data-pipeline">customer order pipeline<br />
												</a></h2>
											</header>
											<a href="https://github.com/Nelsonchris1/ML-explainability-app" ><img src="https://p2zk82o7hr3yb6ge7gzxx4ki-wpengine.netdna-ssl.com/wp-content/uploads/2017/10/1-yaTKFg6K8tTPXJtBUZ0_lw.png" alt="" /></a>
											<p>In this project, i created a streaming data pipeline with kafka using confluent cloud which is a fully managed apache kafka service.
												 i also explored aws lambda (a servelerless event driven compute service). Kafka streams the messages produced by datagenconnector,
												  S3connector consumes the message and stores it in an s3 bucket, Lambda function to clean and process the raw data is triggered by eventbridge on the rule of object created, and finally this clean data is stored in an s3 bucket while recording the runs. Lambda is deployed using Terraform </p>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/ML-explainability-app" class="button">Github Repo</a></li>
											</ul>
										</article>
										<article>
											<header>
												<span class="date">Machine learning</span>
												<h2><a href="https://github.com/Nelsonchris1/ML-explainability-app">Explain My Model<br />
												</a></h2>
											</header>
											<a href="https://github.com/Nelsonchris1/ML-explainability-app" ><img src="images/explain_my_model.PNG" alt="" /></a>
											<p>explainMyModel is an open source webapp built to easily explain Supervised machine learning models merely by dragging and dropping without writing any code. This app is featured in the streamlit gallery <a href="https://streamlit.io/gallery?category=education">click here</a></p>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/ML-explainability-app" class="button">Github Repo</a></li>
											</ul>
										</article>
										<article>
											<header>
												<span class="date">data engineering (Batch pipeline)</span>
												<h2><a href="https://github.com/Nelsonchris1/pizzacon_data_pipeline">Pizzacon</h2>
											</header>
											<a href="https://github.com/Nelsonchris1/pizzacon_data_pipeline" ><img src="images/architecture.PNG" alt="" /></a>
											<p>Pizzaconn is a complete end to end data pipeline that pulls data from a local db store, send it to s3(as a staging area) and from s3 to a cloud data warehouse (redshift). This project used tools and services like postgres, s3, redshift, apache airflow and docker</p>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/pizzacon_data_pipeline" class="button">Github Repo</a></li>
											</ul>
										</article>
										<article>
											<header>
												<span class="date">data Science</span>
												<h2><a href="https://github.com/Nelsonchris1/Tourist-recommedation-system">Tourist Reccommendation system</h2>
											</header>
											<a href="https://github.com/Nelsonchris1/Tourist-recommedation-system" ><img src="images/neptune_ai.jpg" alt="" /></a>
											<p>In this project, we have been instructed as data scientists by our stakeholder
												humtourist.co to come up with a brilliant idea to help make the experience of their client
												worthwhile during their stay in Manhattan, New york city. We came up with an idea to
												create a segmentation and recommendation system which recommends the best venues
												to visit according to collective ratings on each venues and neighborhood to visit based
												on some characteristics. .</p>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/Tourist-recommedation-system" class="button">Github Repo</a></li>
											</ul>
										</article>
										<article>
											<header>
												<span class="date">data engineering</span>
												<h2><a href="https://github.com/Nelsonchris1/Data-pipeline-with-apache-airflow">Sparkify Data Pipepline with apache-airflow</h2>
											</header>
											<a href="https://github.com/Nelsonchris1/Data-pipeline-with-apache-airflow" class="image fit"><img src="images/ETL.png" alt="" /></a>
											<p> Sparkify, has decided that it is time to introduce more automation and monitoring to their data warehouse ETL pipelines and come to the conclusion that the best tool to achieve this is Apache Airflow.
												I have been contacted to create high grade data pipelines that are dynamic and built from reusable tasks, can be monitored, and allow easy backfills. They have also noted that the data quality plays a big part when analyses are executed on top the data warehouse and want to run tests against their datasets after the ETL steps have been executed to catch any discrepancies in the datasets.</p>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/Data-pipeline-with-apache-airflow" class="button">Github Repo</a></li>
											</ul>
										</article>
										<article>
											<header>
												<span class="date">computer vision</span>
												<h2><a href="https://github.com/Nelsonchris1/computer_vision_opencv">Open cv weekly</a></h2>
											</header>
											<a href="https://github.com/Nelsonchris1/computer_vision_opencv"><img src="images/open cv.png" alt="" /></a>
											<p>This project includes weekly learning task for open cv</p>
											<li>
												<ul>A program to detect and remove shadows</ul>
												<ul>A program to filter images and live videos, also wrote a vintage filter for images and live videos</ul>
												<ul>A program to perfom frequency domain filtering to different images.</ul>
											</li>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/computer_vision_opencv" class="button">Github repo</a></li>
											</ul>
										</article>
										<article>
											<header>
												<span class="date">Data Science</span>
												<h2><a href="https://github.com/Nelsonchris1/Sendy-Logistic-challenge">Sendy Logistics</a></h2>
											</header>
											<a href="https://github.com/Nelsonchris1/Sendy-Logistic-challenge"><img src="images/41.jpg" alt="" /></a>
											<p>Sendy Logistic is a logistic company that delivers items to respective customers. In this project, i cleaned the messy data, Joined table, performed analysis on features to find strongly correleted feature and also peform feature enginnering. In the end i predictied the time duration of each logistic driver from pickup to delivery</p>
											<ul class="actions special">
												<li><a href="https://github.com/Nelsonchris1/Sendy-Logistic-challenge" class="button">Github Repo</a></li>
											</ul>
										</article>
									</section>
		
								
									
		
							</div>
		
						<!-- Footer -->
							<footer id="footer">
								
									<section>
										<h3>SOCIAL</h3>
										<ul class="icons alt">
											<li><a href="https://twitter.com/Nelson_Christof" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
											<li><a href="https://www.linkedin.com/in/nelson-ogbeide-013569171/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
											<li><a href="https://github.com/Nelsonchris1" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
										</ul>
									</section>
								
							</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>